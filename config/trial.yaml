# Minimal config for a quick trial run

hardware:
  backend: auto
  dtype: auto
  max_memory_fraction: 0.85

model:
  name: llama-8b
  quantization: auto
  max_new_tokens: 256

vectors:
  extraction_template: "Tell me about {word}."
  token_position: last
  cache_dir: data/vectors
  dataset_path: data/concepts/simple_data.json
  normalize: true

injection:
  apply_to: all

experiments:
  seed: 42
  num_trials: 3
  temperature: 1.0
  output_dir: data/results

  self_report:
    enabled: true
    layers: [12]
    alphas: [4]
    criteria: [coherence, affirmative, correct_identification]

  distinguish:
    enabled: false
  prefill_detect:
    enabled: false
  intentional_control:
    enabled: false

evaluation:
  judge_model: gpt-5-nano-2025-08-07
  max_retries: 3
  retry_delay: 1.0

logging:
  level: INFO
  file: data/logs/trial.log
